# Processando Big Data com Apache Spark

No 7º Capítulo do curso, iniciamos aprendizados sobre Apache Spark, realizando aplicações através do Jupyter Notebook com Processamento PySpark:

<ul>
  <li>Introdução</li>
  <li>Apache Spark e Big Data</li>
  <li>Ecossistema e Componentes do Apache Spark - 3 Partes</li>
  <li>Quando Devemos Usar o Spark?</li>
  <li>Principais Características do Apache Spark</li>
  <li>Verificando a Instalação do Spark</li>
  <li>Introdução ao PySpark</li>
  <li>Executando Aplicação PySpark</li>
  <li>Operação de MapReduce com PySpark</li>
  <li>Hadoop MapReduce x Apache Spark</li>
  <li>O Processo de MapReduce no Apache Spark</li>
  <li>Profissionais que Trabalham com Apache Spark</li>
  <li>Anatomia de uma Aplicação Spark</li>
  <li>Arquitetura Spark</li>
  <li>Spark Modes</li>
  <li>Deploy Mode e Fontes de Dados</li>
  <li>RDD’s – Resilient Distributed Datasets – 2 Partes</li>
  <li>O que são Transformações?</li>
  <li>Principais Operações de Transformação</li>
  <li>Transformações - PySpark</li>
  <li>Operações Set, Outer Join e Distinct</li>
  <li>Transformação e Limpeza</li>
  <li>O que são Ações?</li>
  <li>Ações - PySpark</li>
  <li>Mini-Projeto 1 – Analisando Dados do Uber com Spark - Especificação</li>
</ul>